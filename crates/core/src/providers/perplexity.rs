//! Perplexity API client and Clankers integration
//!
//! # Example
//! ```
//! use clankers::providers::perplexity;
//!
//! let client = perplexity::Client::new("YOUR_API_KEY");
//!
//! let llama_3_1_sonar_small_online = client.completion_model(perplexity::LLAMA_3_1_SONAR_SMALL_ONLINE);
//! ```
use serde::{Deserialize, Serialize};
use tracing::Instrument;

use crate::OneOrMany;
use crate::client::{self, BearerAuth, Capable, Nothing, ProviderClient};
use crate::completion::{self, CompletionError, CompletionRequest, MessageError, message};
use crate::http_client::{self, HttpClientExt};
use crate::providers::openai;
use crate::providers::openai::send_compatible_streaming_request;
use crate::providers::openai_compat::{
	self, CompletionModel, FlatApiError, OpenAiCompat, PBuilder,
};
use crate::streaming::StreamingCompletionResponse;

#[derive(Debug, Default, Clone, Copy)]
pub struct Perplexity;

impl OpenAiCompat for Perplexity {
	const PROVIDER_NAME: &'static str = "perplexity";
	const BASE_URL: &'static str = "https://api.perplexity.ai";
	const API_KEY_ENV: &'static str = "PERPLEXITY_API_KEY";
	const VERIFY_PATH: &'static str = "";
	const COMPLETION_PATH: &'static str = "/chat/completions";
	type BuilderState = ();
	type Completion<H> = Capable<CompletionModel<Self, H>>;
	type Embeddings<H> = Nothing;
	type Transcription<H> = Nothing;
	#[cfg(feature = "image")]
	type ImageGeneration<H> = Nothing;
	#[cfg(feature = "audio")]
	type AudioGeneration<H> = Nothing;
}

pub type Client<H = reqwest::Client> = client::Client<Perplexity, H>;
pub type ClientBuilder<H = reqwest::Client> =
	client::ClientBuilder<PBuilder<Perplexity>, BearerAuth, H>;

impl ProviderClient for Client {
	type Input = String;

	fn from_env() -> Self {
		openai_compat::default_from_env::<Perplexity>()
	}

	fn from_val(input: Self::Input) -> Self {
		Self::new(&input).unwrap()
	}
}

// ================================================================
// Perplexity Completion API
// ================================================================

pub const SONAR_PRO: &str = "sonar_pro";
pub const SONAR: &str = "sonar";

#[derive(Debug, Deserialize, Serialize)]
pub struct CompletionResponse {
	pub id: String,
	pub model: String,
	pub object: String,
	pub created: u64,
	#[serde(default)]
	pub choices: Vec<Choice>,
	pub usage: Usage,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct Message {
	pub role: Role,
	pub content: String,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum Role {
	System,
	User,
	Assistant,
}

#[derive(Deserialize, Debug, Serialize)]
pub struct Delta {
	pub role: Role,
	pub content: String,
}

#[derive(Deserialize, Debug, Serialize)]
pub struct Choice {
	pub index: usize,
	pub finish_reason: String,
	pub message: Message,
	pub delta: Delta,
}

#[derive(Deserialize, Debug, Serialize)]
pub struct Usage {
	pub prompt_tokens: u32,
	pub completion_tokens: u32,
	pub total_tokens: u32,
}

impl std::fmt::Display for Usage {
	fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
		write!(
			f,
			"Prompt tokens: {}\nCompletion tokens: {} Total tokens: {}",
			self.prompt_tokens, self.completion_tokens, self.total_tokens
		)
	}
}

impl TryFrom<CompletionResponse> for completion::CompletionResponse<CompletionResponse> {
	type Error = CompletionError;

	fn try_from(response: CompletionResponse) -> Result<Self, Self::Error> {
		let choice = response.choices.first().ok_or_else(|| {
			CompletionError::ResponseError("Response contained no choices".to_owned())
		})?;

		match &choice.message {
			Message {
				role: Role::Assistant,
				content,
			} => Ok(completion::CompletionResponse {
				choice: OneOrMany::one(content.clone().into()),
				usage: completion::Usage {
					input_tokens: response.usage.prompt_tokens as u64,
					output_tokens: response.usage.completion_tokens as u64,
					total_tokens: response.usage.total_tokens as u64,
					cached_input_tokens: 0,
				},
				raw_response: response,
			}),
			_ => Err(CompletionError::ResponseError(
				"Response contained no assistant message".to_owned(),
			)),
		}
	}
}

#[derive(Debug, Serialize, Deserialize)]
pub(super) struct PerplexityCompletionRequest {
	model: String,
	pub messages: Vec<Message>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub temperature: Option<f64>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub max_tokens: Option<u64>,
	#[serde(flatten, skip_serializing_if = "Option::is_none")]
	additional_params: Option<serde_json::Value>,
	pub stream: bool,
}

impl TryFrom<(&str, CompletionRequest)> for PerplexityCompletionRequest {
	type Error = CompletionError;

	fn try_from((model, req): (&str, CompletionRequest)) -> Result<Self, Self::Error> {
		let mut partial_history = vec![];
		if let Some(docs) = req.normalized_documents() {
			partial_history.push(docs);
		}
		partial_history.extend(req.chat_history);

		// Initialize full history with preamble (or empty if non-existent)
		let mut full_history: Vec<Message> = req.preamble.map_or_else(Vec::new, |preamble| {
			vec![Message {
				role: Role::System,
				content: preamble,
			}]
		});

		// Convert and extend the rest of the history
		full_history.extend(
			partial_history
				.into_iter()
				.map(message::Message::try_into)
				.collect::<Result<Vec<Message>, _>>()?,
		);

		Ok(Self {
			model: model.to_string(),
			messages: full_history,
			temperature: req.temperature,
			max_tokens: req.max_tokens,
			additional_params: req.additional_params,
			stream: false,
		})
	}
}

impl TryFrom<message::Message> for Message {
	type Error = MessageError;

	fn try_from(message: message::Message) -> Result<Self, Self::Error> {
		Ok(match message {
			message::Message::User { content } => {
				let collapsed_content = content
					.into_iter()
					.map(|content| match content {
						message::UserContent::Text(message::Text { text }) => Ok(text),
						_ => Err(MessageError::ConversionError(
							"Only text content is supported by Perplexity".to_owned(),
						)),
					})
					.collect::<Result<Vec<_>, _>>()?
					.join("\n");

				Message {
					role: Role::User,
					content: collapsed_content,
				}
			}

			message::Message::Assistant { content, .. } => {
				let collapsed_content = content
					.into_iter()
					.map(|content| {
						Ok(match content {
							message::AssistantContent::Text(message::Text { text }) => text,
							_ => return Err(MessageError::ConversionError(
								"Only text assistant message content is supported by Perplexity"
									.to_owned(),
							)),
						})
					})
					.collect::<Result<Vec<_>, _>>()?
					.join("\n");

				Message {
					role: Role::Assistant,
					content: collapsed_content,
				}
			}
		})
	}
}

impl From<Message> for message::Message {
	fn from(message: Message) -> Self {
		match message.role {
			Role::User => message::Message::user(message.content),
			Role::Assistant => message::Message::assistant(message.content),

			// System messages get coerced into user messages for ease of error handling.
			// They should be handled on the outside of `Message` conversions via the preamble.
			Role::System => message::Message::user(message.content),
		}
	}
}

impl<T> completion::CompletionModel for CompletionModel<Perplexity, T>
where
	T: HttpClientExt + Clone + Default + std::fmt::Debug + Send + 'static,
{
	type Response = CompletionResponse;
	type StreamingResponse = openai::StreamingCompletionResponse;

	type Client = Client<T>;

	fn make(client: &Self::Client, model: impl Into<String>) -> Self {
		Self::new(client.clone(), model)
	}

	async fn completion(
		&self,
		completion_request: completion::CompletionRequest,
	) -> Result<completion::CompletionResponse<CompletionResponse>, CompletionError> {
		let span = openai_compat::completion_span(
			Perplexity::PROVIDER_NAME,
			&self.model,
			&completion_request.preamble,
		);

		if completion_request.tool_choice.is_some() {
			tracing::warn!("WARNING: `tool_choice` not supported on Perplexity");
		}

		if !completion_request.tools.is_empty() {
			tracing::warn!("WARNING: `tools` not supported on Perplexity");
		}

		let request =
			PerplexityCompletionRequest::try_from((self.model.as_ref(), completion_request))?;

		if tracing::enabled!(tracing::Level::TRACE) {
			tracing::trace!(target: "clankers::completions",
				"Perplexity completion request: {}",
				serde_json::to_string_pretty(&request)?
			);
		}

		let body = serde_json::to_vec(&request)?;

		let req = self
			.client
			.post("/chat/completions")?
			.body(body)
			.map_err(http_client::Error::from)?;

		let async_block = async move {
			let response = openai_compat::send_and_parse::<_, CompletionResponse, FlatApiError, _>(
				&self.client,
				req,
				Perplexity::PROVIDER_NAME,
			)
			.await?;

			// Record span fields manually for Perplexity
			let current_span = tracing::Span::current();
			current_span.record("gen_ai.usage.input_tokens", response.usage.prompt_tokens);
			current_span.record(
				"gen_ai.usage.output_tokens",
				response.usage.completion_tokens,
			);
			current_span.record("gen_ai.response.id", response.id.to_string());
			current_span.record("gen_ai.response.model", response.model.to_string());

			if tracing::enabled!(tracing::Level::TRACE) {
				tracing::trace!(target: "clankers::responses",
					"Perplexity completion response: {}",
					serde_json::to_string_pretty(&response)?
				);
			}

			response.try_into()
		};

		async_block.instrument(span).await
	}

	async fn stream(
		&self,
		completion_request: completion::CompletionRequest,
	) -> Result<StreamingCompletionResponse<Self::StreamingResponse>, CompletionError> {
		let span = openai_compat::streaming_span(
			Perplexity::PROVIDER_NAME,
			&self.model,
			&completion_request.preamble,
		);

		if completion_request.tool_choice.is_some() {
			tracing::warn!("WARNING: `tool_choice` not supported on Perplexity");
		}

		if !completion_request.tools.is_empty() {
			tracing::warn!("WARNING: `tools` not supported on Perplexity");
		}

		let mut request =
			PerplexityCompletionRequest::try_from((self.model.as_ref(), completion_request))?;
		request.stream = true;

		if tracing::enabled!(tracing::Level::TRACE) {
			tracing::trace!(target: "clankers::completions",
				"Perplexity streaming completion request: {}",
				serde_json::to_string_pretty(&request)?
			);
		}

		let body = serde_json::to_vec(&request)?;

		let req = self
			.client
			.post("/chat/completions")?
			.body(body)
			.map_err(http_client::Error::from)?;

		send_compatible_streaming_request(self.client.clone(), req)
			.instrument(span)
			.await
	}
}

#[cfg(test)]
mod tests {
	use super::*;

	#[test]
	fn test_deserialize_message() {
		let json_data = r#"
        {
            "role": "user",
            "content": "Hello, how can I help you?"
        }
        "#;

		let message: Message = serde_json::from_str(json_data).unwrap();
		assert_eq!(message.role, Role::User);
		assert_eq!(message.content, "Hello, how can I help you?");
	}

	#[test]
	fn test_serialize_message() {
		let message = Message {
			role: Role::Assistant,
			content: "I am here to assist you.".to_string(),
		};

		let json_data = serde_json::to_string(&message).unwrap();
		let expected_json = r#"{"role":"assistant","content":"I am here to assist you."}"#;
		assert_eq!(json_data, expected_json);
	}

	#[test]
	fn test_message_to_message_conversion() {
		let user_message = message::Message::user("User message");
		let assistant_message = message::Message::assistant("Assistant message");

		let converted_user_message: Message = user_message.clone().try_into().unwrap();
		let converted_assistant_message: Message = assistant_message.clone().try_into().unwrap();

		assert_eq!(converted_user_message.role, Role::User);
		assert_eq!(converted_user_message.content, "User message");

		assert_eq!(converted_assistant_message.role, Role::Assistant);
		assert_eq!(converted_assistant_message.content, "Assistant message");

		let back_to_user_message: message::Message = converted_user_message.into();
		let back_to_assistant_message: message::Message = converted_assistant_message.into();

		assert_eq!(user_message, back_to_user_message);
		assert_eq!(assistant_message, back_to_assistant_message);
	}
}
